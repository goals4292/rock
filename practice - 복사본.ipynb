{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['paper', 'rock', 'scissors']\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([3, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8152\n",
      "Epoch 2/10, Loss: 0.1450\n",
      "Epoch 3/10, Loss: 0.0385\n",
      "Epoch 4/10, Loss: 0.0234\n",
      "Epoch 5/10, Loss: 0.0115\n",
      "Epoch 6/10, Loss: 0.0128\n",
      "Epoch 7/10, Loss: 0.0116\n",
      "Epoch 8/10, Loss: 0.0051\n",
      "Epoch 9/10, Loss: 0.0115\n",
      "Epoch 10/10, Loss: 0.0071\n",
      "Accuracy: 91.67%\n",
      "Model saved to ./rock_paper_scissors_pretrained_model.pth2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "# 1. 경로 설정\n",
    "data_dir = './Rock-Paper-Scissors'\n",
    "train_dir = os.path.join(data_dir, 'train3')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# 2. 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Pretrained 모델에 맞게 크기 조정\n",
    "    transforms.ToTensor(),          # 텐서로 변환\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 3채널 정규화\n",
    "])\n",
    "\n",
    "# 3. 데이터셋 로드\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 클래스 이름 확인\n",
    "classes = train_dataset.classes\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "# 4. CUDA 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 5. Pretrained 모델 불러오기\n",
    "pretrained_model_name = \"microsoft/resnet-50\"\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    pretrained_model_name,\n",
    "    num_labels=3,  # 가위바위보 3개 클래스로 분류\n",
    "    ignore_mismatched_sizes=True  # Pretrained 모델과 출력 레이어 크기가 다를 때 강제로 맞춤\n",
    ")\n",
    "\n",
    "# Feature Extractor 출력 크기 확인 및 분류기 수정\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Flatten(),  # Feature Map을 1D 벡터로 변환\n",
    "    nn.Linear(2048, 3)  # ResNet Feature Extractor의 출력 크기와 맞춤\n",
    ")\n",
    "\n",
    "# 모델을 GPU 또는 CPU로 이동\n",
    "model = model.to(device)\n",
    "\n",
    "# 6. 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 7. 학습 루프\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # 데이터를 GPU로 전송\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs.logits, labels)  # Loss 계산 (logits 사용)\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Optimizer 업데이트\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 8. 평가 루프\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # 데이터를 GPU로 전송\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# 9. 모델 저장 함수 추가\n",
    "def save_model(model, save_path):\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "# 10. 모델 학습\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "# 11. 모델 평가\n",
    "evaluate_model(model, test_loader)\n",
    "\n",
    "# 12. 학습한 모델 저장\n",
    "save_path = './rock_paper_scissors_pretrained_model.pth2'\n",
    "save_model(model, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([3, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to exit.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "# 1. 모델 불러오기\n",
    "model_path = './rock_paper_scissors_pretrained_model.pth'\n",
    "pretrained_model_name = \"microsoft/resnet-50\"\n",
    "\n",
    "# Pretrained 모델 로드\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    pretrained_model_name,\n",
    "    num_labels=3,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, 3)  # 가위, 바위, 보\n",
    ")\n",
    "\n",
    "# 모델 가중치 불러오기\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# CUDA 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 클래스 이름\n",
    "classes = ['paper', 'rock', 'scissors']\n",
    "\n",
    "# 2. 이미지 전처리 함수\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),  # 모델 입력 크기에 맞게 조정\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 학습 시 정규화와 동일\n",
    "])\n",
    "\n",
    "# 3. 실시간 카메라 캡처\n",
    "cap = cv2.VideoCapture(0)  # 웹캠 열기\n",
    "if not cap.isOpened():\n",
    "    print(\"Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Press 'q' to exit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    # 화면에 프레임 출력\n",
    "    cv2.imshow(\"Rock-Paper-Scissors Classifier\", frame)\n",
    "\n",
    "    # 프레임 중앙 부분을 잘라내기 (옵션)\n",
    "    h, w, _ = frame.shape\n",
    "    min_dim = min(h, w)\n",
    "    crop_img = frame[(h - min_dim) // 2:(h + min_dim) // 2, (w - min_dim) // 2:(w + min_dim) // 2]\n",
    "\n",
    "    # 이미지 전처리\n",
    "    input_image = transform(crop_img).unsqueeze(0).to(device)\n",
    "\n",
    "    # 모델 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_image)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        predicted_class = classes[predicted.item()]\n",
    "\n",
    "    # 예측 결과 출력\n",
    "    cv2.putText(frame, f\"Prediction: {predicted_class}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # 화면에 표시\n",
    "    cv2.imshow(\"Rock-Paper-Scissors Classifier\", frame)\n",
    "\n",
    "    # 'q' 키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 카메라 및 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

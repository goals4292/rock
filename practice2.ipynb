{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaeyung\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\jaeyung\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe0f78af3f942d4acd28425b3816c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaeyung\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jaeyung\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf9056858234c0e863006902d1b7cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb7cf0443904ce19a2f140ed3d02ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3172e7ad1de34f209ed97dfc1ed7ae2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998641014099121}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 감성 분석 파이프라인 로드\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# 테스트 텍스트 입력\n",
    "result = classifier(\"I love Hugging Face!\")\n",
    "print(result)\n",
    "# 출력: [{'label': 'POSITIVE', 'score': 0.99}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f55489426164acf980620ff4d220e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaeyung\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\jaeyung\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd0bffa4c3e42ef945ff5c0cf34054f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08734bb575a54ae6b54dc24ca965e07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6680db0402a346cc89454e42b9ff951e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 전 모델 구조:\n",
      ": DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "distilbert: DistilBertModel(\n",
      "  (embeddings): Embeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (layer): ModuleList(\n",
      "      (0-5): 6 x TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "distilbert.embeddings: Embeddings(\n",
      "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "  (position_embeddings): Embedding(512, 768)\n",
      "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "distilbert.embeddings.word_embeddings: Embedding(30522, 768, padding_idx=0)\n",
      "distilbert.embeddings.position_embeddings: Embedding(512, 768)\n",
      "distilbert.embeddings.LayerNorm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.embeddings.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer: Transformer(\n",
      "  (layer): ModuleList(\n",
      "    (0-5): 6 x TransformerBlock(\n",
      "      (attention): MultiHeadSelfAttention(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (ffn): FFN(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "distilbert.transformer.layer: ModuleList(\n",
      "  (0-5): 6 x TransformerBlock(\n",
      "    (attention): MultiHeadSelfAttention(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "    (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (ffn): FFN(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "distilbert.transformer.layer.0: TransformerBlock(\n",
      "  (attention): MultiHeadSelfAttention(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (ffn): FFN(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (activation): GELUActivation()\n",
      "  )\n",
      "  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      ")\n",
      "distilbert.transformer.layer.0.attention: MultiHeadSelfAttention(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "distilbert.transformer.layer.0.attention.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.0.attention.q_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.0.attention.k_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.0.attention.v_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.0.attention.out_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.0.sa_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.transformer.layer.0.ffn: FFN(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "distilbert.transformer.layer.0.ffn.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.0.ffn.lin1: Linear(in_features=768, out_features=3072, bias=True)\n",
      "distilbert.transformer.layer.0.ffn.lin2: Linear(in_features=3072, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.0.ffn.activation: GELUActivation()\n",
      "distilbert.transformer.layer.0.output_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.transformer.layer.1: TransformerBlock(\n",
      "  (attention): MultiHeadSelfAttention(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (ffn): FFN(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (activation): GELUActivation()\n",
      "  )\n",
      "  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      ")\n",
      "distilbert.transformer.layer.1.attention: MultiHeadSelfAttention(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "distilbert.transformer.layer.1.attention.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.1.attention.q_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.1.attention.k_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.1.attention.v_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.1.attention.out_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.1.sa_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.transformer.layer.1.ffn: FFN(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "distilbert.transformer.layer.1.ffn.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.1.ffn.lin1: Linear(in_features=768, out_features=3072, bias=True)\n",
      "distilbert.transformer.layer.1.ffn.lin2: Linear(in_features=3072, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.1.ffn.activation: GELUActivation()\n",
      "distilbert.transformer.layer.1.output_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.transformer.layer.2: TransformerBlock(\n",
      "  (attention): MultiHeadSelfAttention(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (ffn): FFN(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (activation): GELUActivation()\n",
      "  )\n",
      "  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      ")\n",
      "distilbert.transformer.layer.2.attention: MultiHeadSelfAttention(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "distilbert.transformer.layer.2.attention.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.2.attention.q_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.2.attention.k_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.2.attention.v_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.2.attention.out_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.2.sa_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.transformer.layer.2.ffn: FFN(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "distilbert.transformer.layer.2.ffn.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.2.ffn.lin1: Linear(in_features=768, out_features=3072, bias=True)\n",
      "distilbert.transformer.layer.2.ffn.lin2: Linear(in_features=3072, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.2.ffn.activation: GELUActivation()\n",
      "distilbert.transformer.layer.2.output_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.transformer.layer.3: TransformerBlock(\n",
      "  (attention): MultiHeadSelfAttention(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (ffn): FFN(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (activation): GELUActivation()\n",
      "  )\n",
      "  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      ")\n",
      "distilbert.transformer.layer.3.attention: MultiHeadSelfAttention(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "distilbert.transformer.layer.3.attention.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.3.attention.q_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.3.attention.k_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.3.attention.v_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.3.attention.out_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.3.sa_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.transformer.layer.3.ffn: FFN(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "distilbert.transformer.layer.3.ffn.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.3.ffn.lin1: Linear(in_features=768, out_features=3072, bias=True)\n",
      "distilbert.transformer.layer.3.ffn.lin2: Linear(in_features=3072, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.3.ffn.activation: GELUActivation()\n",
      "distilbert.transformer.layer.3.output_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.transformer.layer.4: TransformerBlock(\n",
      "  (attention): MultiHeadSelfAttention(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (ffn): FFN(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (activation): GELUActivation()\n",
      "  )\n",
      "  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      ")\n",
      "distilbert.transformer.layer.4.attention: MultiHeadSelfAttention(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "distilbert.transformer.layer.4.attention.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.4.attention.q_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.4.attention.k_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.4.attention.v_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.4.attention.out_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.4.sa_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.transformer.layer.4.ffn: FFN(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "distilbert.transformer.layer.4.ffn.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.4.ffn.lin1: Linear(in_features=768, out_features=3072, bias=True)\n",
      "distilbert.transformer.layer.4.ffn.lin2: Linear(in_features=3072, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.4.ffn.activation: GELUActivation()\n",
      "distilbert.transformer.layer.4.output_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.transformer.layer.5: TransformerBlock(\n",
      "  (attention): MultiHeadSelfAttention(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (ffn): FFN(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "    (activation): GELUActivation()\n",
      "  )\n",
      "  (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      ")\n",
      "distilbert.transformer.layer.5.attention: MultiHeadSelfAttention(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      ")\n",
      "distilbert.transformer.layer.5.attention.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.5.attention.q_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.5.attention.k_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.5.attention.v_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.5.attention.out_lin: Linear(in_features=768, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.5.sa_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "distilbert.transformer.layer.5.ffn: FFN(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (activation): GELUActivation()\n",
      ")\n",
      "distilbert.transformer.layer.5.ffn.dropout: Dropout(p=0.1, inplace=False)\n",
      "distilbert.transformer.layer.5.ffn.lin1: Linear(in_features=768, out_features=3072, bias=True)\n",
      "distilbert.transformer.layer.5.ffn.lin2: Linear(in_features=3072, out_features=768, bias=True)\n",
      "distilbert.transformer.layer.5.ffn.activation: GELUActivation()\n",
      "distilbert.transformer.layer.5.output_layer_norm: LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "pre_classifier: Linear(in_features=768, out_features=768, bias=True)\n",
      "classifier: Linear(in_features=768, out_features=2, bias=True)\n",
      "dropout: Dropout(p=0.2, inplace=False)\n",
      "\n",
      "Pruning 후 모델 구조:\n",
      "distilbert.transformer.layer.0.attention.q_lin.weight_pruned: tensor([[-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0587,  0.0478],\n",
      "        [ 0.0000,  0.0000, -0.0566,  ..., -0.0000,  0.1362,  0.0000],\n",
      "        [-0.0000,  0.0303,  0.0000,  ..., -0.0000,  0.0000, -0.0429],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0000,  0.0731,  ...,  0.0685,  0.0450, -0.0310],\n",
      "        [ 0.0000,  0.0874,  0.0822,  ..., -0.0000,  0.1134,  0.0000],\n",
      "        [-0.0000, -0.0893,  0.0000,  ..., -0.0461, -0.0988, -0.0329]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.0.attention.k_lin.weight_pruned: tensor([[ 0.0328, -0.0552, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0000, -0.0346,  0.0300,  ..., -0.0448, -0.0000,  0.0000],\n",
      "        [ 0.0314, -0.0000, -0.0000,  ...,  0.0000, -0.0285,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0335, -0.0689,  ...,  0.0307, -0.0000,  0.0953],\n",
      "        [-0.0527,  0.0000, -0.0000,  ..., -0.0424, -0.0504, -0.1072],\n",
      "        [-0.0000, -0.0000,  0.0000,  ..., -0.0493,  0.0562,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.0.attention.v_lin.weight_pruned: tensor([[ 0.0264,  0.0000,  0.0000,  ...,  0.0491, -0.0000, -0.0000],\n",
      "        [-0.0540, -0.0000, -0.0403,  ...,  0.0679, -0.0305, -0.0000],\n",
      "        [ 0.0458, -0.0260,  0.0294,  ...,  0.0000, -0.0622, -0.0261],\n",
      "        ...,\n",
      "        [-0.0467, -0.0000,  0.0411,  ..., -0.0000, -0.0414, -0.0000],\n",
      "        [-0.0000,  0.0723,  0.0238,  ...,  0.0294,  0.0000, -0.0000],\n",
      "        [-0.0000, -0.0333, -0.0000,  ..., -0.0376, -0.0634, -0.0357]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.0.attention.out_lin.weight_pruned: tensor([[-0.0276, -0.0437,  0.0000,  ..., -0.0313, -0.0000,  0.0436],\n",
      "        [ 0.0463,  0.0000,  0.0000,  ..., -0.0000,  0.0432,  0.0000],\n",
      "        [-0.0452, -0.0314,  0.0243,  ..., -0.0000,  0.0324, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0273,  0.0000,  0.0664,  ..., -0.0000,  0.0288, -0.0000],\n",
      "        [ 0.0000, -0.0000, -0.0621,  ...,  0.0612, -0.0390, -0.0701],\n",
      "        [-0.0663, -0.0000, -0.0515,  ...,  0.0466,  0.0000, -0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.0.ffn.lin1.weight_pruned: tensor([[-0.0378,  0.0000, -0.0000,  ..., -0.0812, -0.0000, -0.0000],\n",
      "        [-0.0768, -0.0000,  0.0720,  ..., -0.0400, -0.0623,  0.0000],\n",
      "        [ 0.0000,  0.0760,  0.0356,  ...,  0.0000,  0.0000, -0.0401],\n",
      "        ...,\n",
      "        [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0478],\n",
      "        [ 0.0786, -0.0652,  0.0429,  ...,  0.0000,  0.0408,  0.0000],\n",
      "        [-0.0000,  0.0318,  0.0302,  ...,  0.0000,  0.0279,  0.0354]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.0.ffn.lin2.weight_pruned: tensor([[-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0291,  0.0320],\n",
      "        [ 0.0455,  0.0000,  0.0615,  ..., -0.0000, -0.0549, -0.0000],\n",
      "        [-0.0361, -0.0343,  0.0775,  ..., -0.0000,  0.0308,  0.0000],\n",
      "        ...,\n",
      "        [-0.0500, -0.0000,  0.0279,  ...,  0.0000,  0.0269,  0.0000],\n",
      "        [-0.0758,  0.0296,  0.0000,  ..., -0.0000, -0.0888,  0.0385],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0612,  0.0000,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.1.attention.q_lin.weight_pruned: tensor([[ 0.0905, -0.0000, -0.0768,  ..., -0.0000, -0.0988, -0.0000],\n",
      "        [ 0.0872, -0.0000, -0.0553,  ...,  0.1269, -0.0000, -0.0000],\n",
      "        [ 0.0652,  0.0382, -0.0708,  ...,  0.0387, -0.0543,  0.0769],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0896, -0.0800,  ...,  0.0000, -0.0000, -0.0561],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0857, -0.0000, -0.0000],\n",
      "        [-0.0674, -0.0364, -0.0000,  ..., -0.0000, -0.0000,  0.0373]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.1.attention.k_lin.weight_pruned: tensor([[ 0.0857,  0.0776,  0.0492,  ..., -0.0862,  0.1634, -0.0000],\n",
      "        [-0.0000,  0.0608, -0.0000,  ...,  0.1553,  0.0758, -0.0000],\n",
      "        [-0.0000,  0.0613, -0.0474,  ..., -0.0430,  0.0914,  0.0000],\n",
      "        ...,\n",
      "        [-0.0384,  0.0906, -0.0000,  ..., -0.0000, -0.0735, -0.0000],\n",
      "        [-0.0362, -0.0544,  0.0000,  ..., -0.0565,  0.0541,  0.0000],\n",
      "        [-0.0000,  0.1035, -0.0656,  ..., -0.0000,  0.0000,  0.0760]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.1.attention.v_lin.weight_pruned: tensor([[-0.0000, -0.0607, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0287, -0.0306],\n",
      "        [-0.0000, -0.0000, -0.0548,  ..., -0.0314,  0.0518, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0830,  0.0000,  ..., -0.0000,  0.0000, -0.0523],\n",
      "        [-0.0000,  0.0342,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [-0.0519, -0.0000, -0.0426,  ...,  0.0000,  0.0000, -0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.1.attention.out_lin.weight_pruned: tensor([[ 0.0000,  0.0000, -0.0473,  ..., -0.0584, -0.0802,  0.0627],\n",
      "        [ 0.0000,  0.0581, -0.0000,  ...,  0.0000, -0.0407,  0.0336],\n",
      "        [ 0.0339, -0.0405,  0.0000,  ...,  0.0259,  0.0000, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0388, -0.0225, -0.0246,  ..., -0.0000, -0.0000, -0.0243],\n",
      "        [-0.0000, -0.0602,  0.0520,  ...,  0.0000,  0.0401, -0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0322,  ..., -0.0000, -0.0260,  0.0289]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.1.ffn.lin1.weight_pruned: tensor([[ 0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0702],\n",
      "        [ 0.0000, -0.0430,  0.0000,  ...,  0.1092, -0.0000,  0.0000],\n",
      "        [-0.0000, -0.0000,  0.0379,  ...,  0.0784, -0.0000,  0.0392],\n",
      "        ...,\n",
      "        [-0.0000,  0.0000, -0.0486,  ...,  0.0328,  0.0000, -0.0000],\n",
      "        [-0.0524, -0.0347,  0.0307,  ..., -0.0291,  0.0652,  0.0000],\n",
      "        [ 0.0000, -0.0390, -0.0431,  ...,  0.1145,  0.0533,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.1.ffn.lin2.weight_pruned: tensor([[-0.0520,  0.0298,  0.0000,  ..., -0.0322, -0.0327,  0.0301],\n",
      "        [-0.0371,  0.0000,  0.0000,  ..., -0.0646, -0.0000, -0.0000],\n",
      "        [ 0.0479, -0.0000,  0.0000,  ..., -0.0377,  0.0416,  0.0482],\n",
      "        ...,\n",
      "        [ 0.0320, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [ 0.0510, -0.0000, -0.0664,  ..., -0.0674,  0.0000,  0.0000],\n",
      "        [-0.0000, -0.0325,  0.0000,  ...,  0.0427, -0.0337,  0.0512]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.2.attention.q_lin.weight_pruned: tensor([[ 0.0732,  0.0574,  0.0000,  ..., -0.0000,  0.0801,  0.0328],\n",
      "        [ 0.0394,  0.0000, -0.0605,  ...,  0.0552,  0.0892, -0.0000],\n",
      "        [ 0.0768,  0.0443,  0.0000,  ..., -0.0761,  0.0315,  0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.0752,  ...,  0.0000,  0.0000,  0.0520],\n",
      "        [-0.0336, -0.0000, -0.1241,  ..., -0.0435,  0.0957, -0.0345],\n",
      "        [-0.0554, -0.0000,  0.0367,  ...,  0.0000, -0.0346,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.2.attention.k_lin.weight_pruned: tensor([[ 0.0909, -0.0771,  0.0000,  ..., -0.0316, -0.0365,  0.0000],\n",
      "        [ 0.0652, -0.0000,  0.0000,  ..., -0.0403, -0.0000, -0.0000],\n",
      "        [-0.0539,  0.0000, -0.1003,  ..., -0.0567,  0.0614, -0.0484],\n",
      "        ...,\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.1444, -0.0373,  0.0668],\n",
      "        [ 0.0000,  0.0412,  0.0000,  ...,  0.0495, -0.1134,  0.0000],\n",
      "        [ 0.0000,  0.0547, -0.0492,  ...,  0.0675,  0.0000,  0.0450]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.2.attention.v_lin.weight_pruned: tensor([[ 0.0679,  0.0000, -0.0433,  ..., -0.0584,  0.0000,  0.0000],\n",
      "        [ 0.0553,  0.0000, -0.0428,  ..., -0.0390, -0.0595, -0.0000],\n",
      "        [ 0.0000, -0.0000,  0.0405,  ...,  0.0551,  0.0723, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0447, -0.0000,  ..., -0.0364, -0.0000, -0.0000],\n",
      "        [ 0.0280,  0.0000, -0.0429,  ...,  0.0000, -0.0000, -0.0391],\n",
      "        [-0.0000, -0.0000, -0.0342,  ..., -0.0282,  0.1395,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.2.attention.out_lin.weight_pruned: tensor([[ 0.0428,  0.0393,  0.0000,  ...,  0.0000, -0.0388,  0.0000],\n",
      "        [-0.0328,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0515],\n",
      "        [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0873],\n",
      "        ...,\n",
      "        [-0.0998, -0.0270, -0.0000,  ...,  0.0908,  0.0000, -0.0648],\n",
      "        [-0.0000, -0.0488,  0.0580,  ...,  0.0401, -0.0495,  0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0298,  0.0000, -0.0499]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.2.ffn.lin1.weight_pruned: tensor([[-0.0000, -0.0408,  0.0000,  ..., -0.0668, -0.0502, -0.0000],\n",
      "        [ 0.0676,  0.0000,  0.0807,  ...,  0.0729, -0.1067,  0.0302],\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.0616,  0.0388, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000,  0.0395,  0.0585,  ..., -0.0656, -0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0000, -0.0300,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0460,  0.0299,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.2.ffn.lin2.weight_pruned: tensor([[-0.0606,  0.0437, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [ 0.0527,  0.0000,  0.0498,  ..., -0.0000,  0.0392,  0.0000],\n",
      "        [ 0.0000,  0.0710, -0.0334,  ...,  0.0000, -0.0338, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.0600,  ...,  0.0288,  0.0306, -0.0560],\n",
      "        [ 0.0000,  0.0424,  0.0000,  ..., -0.0799, -0.0000, -0.0409],\n",
      "        [-0.0508, -0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.3.attention.q_lin.weight_pruned: tensor([[ 0.0000, -0.0843,  0.0000,  ...,  0.0000, -0.0000,  0.0554],\n",
      "        [-0.0000, -0.0525, -0.0368,  ..., -0.0449, -0.0000, -0.0407],\n",
      "        [ 0.0630, -0.0327, -0.0424,  ...,  0.0000,  0.0364, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000, -0.0000,  ..., -0.0616,  0.0000,  0.0000],\n",
      "        [-0.0000,  0.0417, -0.0480,  ..., -0.0000,  0.0771,  0.0000],\n",
      "        [-0.0717,  0.0000, -0.0000,  ...,  0.0558, -0.0000,  0.0401]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.3.attention.k_lin.weight_pruned: tensor([[ 0.0475,  0.0000,  0.0808,  ..., -0.0585,  0.0615,  0.0000],\n",
      "        [-0.0000,  0.0000, -0.1386,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0520, -0.0903,  0.0468],\n",
      "        ...,\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  0.0347, -0.0000, -0.0637],\n",
      "        [-0.0915, -0.0937, -0.0000,  ...,  0.1248,  0.0000,  0.0373],\n",
      "        [ 0.0000,  0.1058,  0.0000,  ..., -0.0000, -0.0499,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.3.attention.v_lin.weight_pruned: tensor([[-0.0000,  0.0000, -0.0000,  ...,  0.0643, -0.1072, -0.0000],\n",
      "        [-0.0629,  0.0361, -0.0300,  ...,  0.0448,  0.0470, -0.0411],\n",
      "        [ 0.0371, -0.0000,  0.0000,  ...,  0.1251, -0.0949, -0.0492],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0474, -0.0651,  ..., -0.0000,  0.0466,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0588,  0.0000, -0.0527],\n",
      "        [ 0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0378, -0.1208]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.3.attention.out_lin.weight_pruned: tensor([[-0.0701,  0.0000,  0.0000,  ..., -0.0974,  0.0403, -0.0443],\n",
      "        [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0445, -0.0349],\n",
      "        [ 0.0389, -0.1020, -0.0721,  ..., -0.0000,  0.1096,  0.0487],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0687, -0.0784,  ..., -0.0419,  0.0000, -0.0768],\n",
      "        [-0.0280, -0.0802, -0.0000,  ...,  0.0848,  0.0600,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0512,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.3.ffn.lin1.weight_pruned: tensor([[ 0.0000, -0.0000, -0.0000,  ...,  0.0383, -0.0587,  0.0281],\n",
      "        [-0.1149, -0.0000,  0.0000,  ...,  0.0000,  0.0564,  0.0445],\n",
      "        [ 0.0000, -0.0000, -0.0438,  ..., -0.0751, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0344,  0.0000],\n",
      "        [ 0.0341,  0.0000,  0.0000,  ...,  0.0000,  0.0711, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0769,  ...,  0.0395,  0.0000, -0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.3.ffn.lin2.weight_pruned: tensor([[-0.0000, -0.1031,  0.0305,  ..., -0.0000,  0.0000, -0.0000],\n",
      "        [-0.0320, -0.0282,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0596,  0.0606,  0.0000],\n",
      "        ...,\n",
      "        [-0.1088,  0.0478, -0.0000,  ..., -0.0540,  0.1234,  0.0000],\n",
      "        [ 0.0000,  0.0901,  0.0461,  ...,  0.0000,  0.0888, -0.0000],\n",
      "        [-0.0548,  0.0341, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.4.attention.q_lin.weight_pruned: tensor([[ 0.0528,  0.0000, -0.0686,  ..., -0.0460,  0.0000,  0.0513],\n",
      "        [-0.0407, -0.0710, -0.0884,  ...,  0.0000, -0.0000,  0.0399],\n",
      "        [-0.0000,  0.0508,  0.0488,  ..., -0.0451,  0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0375],\n",
      "        [ 0.0437,  0.0754, -0.0566,  ...,  0.0000,  0.0000, -0.0000],\n",
      "        [-0.0432, -0.0000,  0.0786,  ..., -0.0804, -0.0567,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.4.attention.k_lin.weight_pruned: tensor([[-0.0000, -0.0000, -0.0526,  ...,  0.0427,  0.0000,  0.0000],\n",
      "        [-0.0000, -0.0499, -0.0594,  ...,  0.0541, -0.0342,  0.0000],\n",
      "        [-0.0537,  0.0000, -0.0000,  ..., -0.0595, -0.0735, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0337,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "        [-0.0413, -0.0796, -0.0000,  ...,  0.0000, -0.0905, -0.0372],\n",
      "        [ 0.0573,  0.0424, -0.0485,  ...,  0.0805,  0.0353, -0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.4.attention.v_lin.weight_pruned: tensor([[-0.0514,  0.0000,  0.0000,  ...,  0.0432,  0.0000,  0.1240],\n",
      "        [-0.0382,  0.0000, -0.0604,  ...,  0.0381,  0.0000,  0.0344],\n",
      "        [ 0.0000, -0.0434,  0.0000,  ...,  0.0000, -0.0000, -0.0428],\n",
      "        ...,\n",
      "        [-0.0000,  0.0628, -0.0631,  ...,  0.0914, -0.0000,  0.0399],\n",
      "        [ 0.0000,  0.0547, -0.0000,  ..., -0.0380,  0.0000, -0.0607],\n",
      "        [ 0.0000,  0.0579, -0.0477,  ...,  0.0342, -0.0000,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.4.attention.out_lin.weight_pruned: tensor([[-0.0000,  0.0326,  0.0000,  ...,  0.0342, -0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0000, -0.0314,  ..., -0.0700,  0.0000, -0.0435],\n",
      "        [-0.0000, -0.0565, -0.0000,  ...,  0.0000,  0.0475, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000,  0.0556,  ..., -0.0326, -0.0464, -0.0000],\n",
      "        [-0.0000, -0.0666,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0361,  0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.4.ffn.lin1.weight_pruned: tensor([[ 0.0543,  0.0000,  0.0393,  ...,  0.0607,  0.0334, -0.0357],\n",
      "        [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0440],\n",
      "        [-0.0741, -0.0000,  0.0000,  ..., -0.0000,  0.0465, -0.0410],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0475,  0.0000],\n",
      "        [-0.0000,  0.0409, -0.0000,  ...,  0.0000,  0.0754, -0.0658],\n",
      "        [ 0.0682, -0.0000, -0.0777,  ..., -0.1028,  0.0511,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.4.ffn.lin2.weight_pruned: tensor([[ 0.0477,  0.0000, -0.0424,  ..., -0.0267,  0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "        [ 0.0000, -0.0336,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.0414,  ...,  0.0000, -0.0501, -0.0328],\n",
      "        [-0.0000, -0.0528, -0.0266,  ..., -0.0412,  0.0641, -0.0393],\n",
      "        [-0.0000,  0.0000, -0.0689,  ..., -0.0497,  0.0534, -0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.5.attention.q_lin.weight_pruned: tensor([[-0.0558, -0.0441, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0889, -0.0000,  0.0000,  ..., -0.0000, -0.0551, -0.0516],\n",
      "        [-0.0000,  0.0507, -0.0646,  ..., -0.0000, -0.0000, -0.0427],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000, -0.0473,  ..., -0.0645, -0.0000,  0.0000],\n",
      "        [ 0.0734, -0.0000,  0.0751,  ..., -0.0000, -0.0673, -0.0000],\n",
      "        [-0.0000,  0.0000, -0.0000,  ...,  0.0326,  0.0375, -0.0435]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.5.attention.k_lin.weight_pruned: tensor([[ 0.0391, -0.0000, -0.0669,  ..., -0.0000,  0.1243, -0.0000],\n",
      "        [-0.0000, -0.0392,  0.0581,  ..., -0.0983,  0.0418,  0.0000],\n",
      "        [-0.0598,  0.0382,  0.0000,  ..., -0.0384,  0.0000,  0.0440],\n",
      "        ...,\n",
      "        [ 0.0515, -0.0519, -0.0000,  ...,  0.0630, -0.0424,  0.0000],\n",
      "        [ 0.0000, -0.0000,  0.0621,  ...,  0.0592, -0.0381,  0.0410],\n",
      "        [ 0.0585,  0.0365, -0.0000,  ...,  0.0883, -0.0000, -0.0374]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.5.attention.v_lin.weight_pruned: tensor([[ 0.0407, -0.0480, -0.0433,  ...,  0.0000,  0.0452, -0.0909],\n",
      "        [ 0.0000, -0.0000,  0.0606,  ..., -0.0000,  0.0000, -0.0503],\n",
      "        [ 0.0000,  0.0504,  0.0933,  ..., -0.0000,  0.0323,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0336,  0.0000, -0.0000,  ...,  0.0540, -0.0000, -0.0000],\n",
      "        [-0.0378, -0.0000, -0.0000,  ...,  0.0893,  0.1245, -0.0000],\n",
      "        [ 0.0000, -0.0000,  0.0418,  ..., -0.1411,  0.0000, -0.0360]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.5.attention.out_lin.weight_pruned: tensor([[ 0.0000,  0.0000,  0.0525,  ...,  0.0000, -0.0000, -0.0310],\n",
      "        [ 0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "        [-0.0385, -0.0000,  0.0660,  ...,  0.0501,  0.0000,  0.0950],\n",
      "        ...,\n",
      "        [-0.0000, -0.0685, -0.0504,  ...,  0.0318,  0.0999, -0.1371],\n",
      "        [-0.0000, -0.1224, -0.1451,  ...,  0.0397,  0.0719,  0.0000],\n",
      "        [-0.0636,  0.0382,  0.0000,  ..., -0.0000, -0.1035,  0.0461]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.5.ffn.lin1.weight_pruned: tensor([[ 0.0626,  0.0735, -0.0000,  ...,  0.0270,  0.0318, -0.0000],\n",
      "        [-0.0000,  0.0000, -0.0340,  ...,  0.0327,  0.0331,  0.0350],\n",
      "        [ 0.0000,  0.0443, -0.0000,  ...,  0.0282,  0.0000, -0.0397],\n",
      "        ...,\n",
      "        [ 0.0571,  0.0000,  0.0358,  ...,  0.0660, -0.0662, -0.0000],\n",
      "        [-0.0398,  0.0595,  0.0000,  ..., -0.0000,  0.0333,  0.0414],\n",
      "        [-0.0465, -0.0543,  0.0307,  ..., -0.0000,  0.0777, -0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "distilbert.transformer.layer.5.ffn.lin2.weight_pruned: tensor([[-0.0000,  0.0000, -0.0000,  ..., -0.0961, -0.0307,  0.0355],\n",
      "        [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0335],\n",
      "        [-0.0000, -0.0404, -0.0265,  ...,  0.0000,  0.0511,  0.1082],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0401,  ..., -0.0000, -0.0286,  0.0000],\n",
      "        [-0.0000,  0.0622, -0.0000,  ..., -0.0556, -0.0000,  0.1087],\n",
      "        [-0.0394,  0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0372]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "pre_classifier.weight_pruned: tensor([[-0.0000, -0.0290, -0.0000,  ..., -0.0243,  0.0000,  0.0219],\n",
      "        [ 0.0279, -0.0000, -0.0317,  ...,  0.0000,  0.0000, -0.0000],\n",
      "        [-0.0306, -0.0000, -0.0000,  ...,  0.0225, -0.0257, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0000, -0.0393,  ...,  0.0352,  0.0186,  0.0181],\n",
      "        [-0.0145,  0.0000,  0.0314,  ...,  0.0551, -0.0312,  0.0233],\n",
      "        [ 0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0219, -0.0194]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "classifier.weight_pruned: tensor([[ 0.0138, -0.0222,  0.0421,  ...,  0.0305, -0.0367, -0.0273],\n",
      "        [-0.0140, -0.0306,  0.0452,  ..., -0.0000, -0.0000, -0.0285]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "\n",
      "테스트 결과: [{'label': 'POSITIVE', 'score': 0.9985686540603638}]\n",
      "\n",
      "Pruned 모델이 저장되었습니다: ./pruned_sentiment_model\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "# 1. 사전 학습된 모델과 토크나이저 로드\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 2. 모델의 가중치 정보 확인\n",
    "print(\"Pruning 전 모델 구조:\")\n",
    "for name, module in model.named_modules():\n",
    "    print(f\"{name}: {module}\")\n",
    "\n",
    "# 3. Pruning 적용 (가중치의 50%를 제거)\n",
    "# distilbert.transformer.layer.*.attention.q_lin 등 중요한 레이어를 지정\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):  # Linear Layer에만 Pruning 적용\n",
    "        prune.l1_unstructured(module, name=\"weight\", amount=0.5)  # 50% 제거\n",
    "\n",
    "# 4. Pruning된 모델의 가중치 확인\n",
    "print(\"\\nPruning 후 모델 구조:\")\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        print(f\"{name}.weight_pruned: {module.weight}\")\n",
    "\n",
    "# 5. 모델 테스트\n",
    "# Pruning 후에도 정상 동작하는지 테스트\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# 입력 문장 테스트\n",
    "test_sentence = \"I love Hugging Face!\"\n",
    "result = classifier(test_sentence)\n",
    "print(\"\\n테스트 결과:\", result)\n",
    "\n",
    "# 6. 모델 저장\n",
    "pruned_model_path = \"./pruned_sentiment_model\"\n",
    "model.save_pretrained(pruned_model_path)\n",
    "tokenizer.save_pretrained(pruned_model_path)\n",
    "\n",
    "print(\"\\nPruned 모델이 저장되었습니다:\", pruned_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./pruned_sentiment_model were not used when initializing DistilBertForSequenceClassification: ['classifier.weight_mask', 'classifier.weight_orig', 'distilbert.transformer.layer.0.attention.k_lin.weight_mask', 'distilbert.transformer.layer.0.attention.k_lin.weight_orig', 'distilbert.transformer.layer.0.attention.out_lin.weight_mask', 'distilbert.transformer.layer.0.attention.out_lin.weight_orig', 'distilbert.transformer.layer.0.attention.q_lin.weight_mask', 'distilbert.transformer.layer.0.attention.q_lin.weight_orig', 'distilbert.transformer.layer.0.attention.v_lin.weight_mask', 'distilbert.transformer.layer.0.attention.v_lin.weight_orig', 'distilbert.transformer.layer.0.ffn.lin1.weight_mask', 'distilbert.transformer.layer.0.ffn.lin1.weight_orig', 'distilbert.transformer.layer.0.ffn.lin2.weight_mask', 'distilbert.transformer.layer.0.ffn.lin2.weight_orig', 'distilbert.transformer.layer.1.attention.k_lin.weight_mask', 'distilbert.transformer.layer.1.attention.k_lin.weight_orig', 'distilbert.transformer.layer.1.attention.out_lin.weight_mask', 'distilbert.transformer.layer.1.attention.out_lin.weight_orig', 'distilbert.transformer.layer.1.attention.q_lin.weight_mask', 'distilbert.transformer.layer.1.attention.q_lin.weight_orig', 'distilbert.transformer.layer.1.attention.v_lin.weight_mask', 'distilbert.transformer.layer.1.attention.v_lin.weight_orig', 'distilbert.transformer.layer.1.ffn.lin1.weight_mask', 'distilbert.transformer.layer.1.ffn.lin1.weight_orig', 'distilbert.transformer.layer.1.ffn.lin2.weight_mask', 'distilbert.transformer.layer.1.ffn.lin2.weight_orig', 'distilbert.transformer.layer.2.attention.k_lin.weight_mask', 'distilbert.transformer.layer.2.attention.k_lin.weight_orig', 'distilbert.transformer.layer.2.attention.out_lin.weight_mask', 'distilbert.transformer.layer.2.attention.out_lin.weight_orig', 'distilbert.transformer.layer.2.attention.q_lin.weight_mask', 'distilbert.transformer.layer.2.attention.q_lin.weight_orig', 'distilbert.transformer.layer.2.attention.v_lin.weight_mask', 'distilbert.transformer.layer.2.attention.v_lin.weight_orig', 'distilbert.transformer.layer.2.ffn.lin1.weight_mask', 'distilbert.transformer.layer.2.ffn.lin1.weight_orig', 'distilbert.transformer.layer.2.ffn.lin2.weight_mask', 'distilbert.transformer.layer.2.ffn.lin2.weight_orig', 'distilbert.transformer.layer.3.attention.k_lin.weight_mask', 'distilbert.transformer.layer.3.attention.k_lin.weight_orig', 'distilbert.transformer.layer.3.attention.out_lin.weight_mask', 'distilbert.transformer.layer.3.attention.out_lin.weight_orig', 'distilbert.transformer.layer.3.attention.q_lin.weight_mask', 'distilbert.transformer.layer.3.attention.q_lin.weight_orig', 'distilbert.transformer.layer.3.attention.v_lin.weight_mask', 'distilbert.transformer.layer.3.attention.v_lin.weight_orig', 'distilbert.transformer.layer.3.ffn.lin1.weight_mask', 'distilbert.transformer.layer.3.ffn.lin1.weight_orig', 'distilbert.transformer.layer.3.ffn.lin2.weight_mask', 'distilbert.transformer.layer.3.ffn.lin2.weight_orig', 'distilbert.transformer.layer.4.attention.k_lin.weight_mask', 'distilbert.transformer.layer.4.attention.k_lin.weight_orig', 'distilbert.transformer.layer.4.attention.out_lin.weight_mask', 'distilbert.transformer.layer.4.attention.out_lin.weight_orig', 'distilbert.transformer.layer.4.attention.q_lin.weight_mask', 'distilbert.transformer.layer.4.attention.q_lin.weight_orig', 'distilbert.transformer.layer.4.attention.v_lin.weight_mask', 'distilbert.transformer.layer.4.attention.v_lin.weight_orig', 'distilbert.transformer.layer.4.ffn.lin1.weight_mask', 'distilbert.transformer.layer.4.ffn.lin1.weight_orig', 'distilbert.transformer.layer.4.ffn.lin2.weight_mask', 'distilbert.transformer.layer.4.ffn.lin2.weight_orig', 'distilbert.transformer.layer.5.attention.k_lin.weight_mask', 'distilbert.transformer.layer.5.attention.k_lin.weight_orig', 'distilbert.transformer.layer.5.attention.out_lin.weight_mask', 'distilbert.transformer.layer.5.attention.out_lin.weight_orig', 'distilbert.transformer.layer.5.attention.q_lin.weight_mask', 'distilbert.transformer.layer.5.attention.q_lin.weight_orig', 'distilbert.transformer.layer.5.attention.v_lin.weight_mask', 'distilbert.transformer.layer.5.attention.v_lin.weight_orig', 'distilbert.transformer.layer.5.ffn.lin1.weight_mask', 'distilbert.transformer.layer.5.ffn.lin1.weight_orig', 'distilbert.transformer.layer.5.ffn.lin2.weight_mask', 'distilbert.transformer.layer.5.ffn.lin2.weight_orig', 'pre_classifier.weight_mask', 'pre_classifier.weight_orig']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at ./pruned_sentiment_model and are newly initialized: ['classifier.weight', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruned 모델 테스트 결과:\n",
      "입력 문장: I love using Hugging Face models!\n",
      "결과: [{'label': 'NEGATIVE', 'score': 0.5189980864524841}]\n",
      "\n",
      "입력 문장: This is a terrible product.\n",
      "결과: [{'label': 'NEGATIVE', 'score': 0.5235587954521179}]\n",
      "\n",
      "입력 문장: The movie was okay, not great but not bad either.\n",
      "결과: [{'label': 'NEGATIVE', 'score': 0.5224853157997131}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "# 저장된 모델 경로\n",
    "pruned_model_path = \"./pruned_sentiment_model\"\n",
    "\n",
    "# 1. 모델과 토크나이저 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pruned_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pruned_model_path)\n",
    "\n",
    "# 2. 파이프라인 생성\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# 3. 테스트 입력\n",
    "test_sentences = [\n",
    "    \"I love using Hugging Face models!\",\n",
    "    \"This is a terrible product.\",\n",
    "    \"The movie was okay, not great but not bad either.\"\n",
    "]\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(\"\\nPruned 모델 테스트 결과:\")\n",
    "for sentence in test_sentences:\n",
    "    result = classifier(sentence)\n",
    "    print(f\"입력 문장: {sentence}\")\n",
    "    print(f\"결과: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 결과: [{'label': 'NEGATIVE', 'score': 0.5180232524871826}]\n"
     ]
    }
   ],
   "source": [
    "# 입력 문장 테스트\n",
    "test_sentence = \"I love Hugging Face!\"\n",
    "result = classifier(test_sentence)\n",
    "print(\"\\n테스트 결과:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./pruned_sentiment_model were not used when initializing DistilBertForSequenceClassification: ['classifier.weight_mask', 'classifier.weight_orig', 'distilbert.transformer.layer.0.attention.k_lin.weight_mask', 'distilbert.transformer.layer.0.attention.k_lin.weight_orig', 'distilbert.transformer.layer.0.attention.out_lin.weight_mask', 'distilbert.transformer.layer.0.attention.out_lin.weight_orig', 'distilbert.transformer.layer.0.attention.q_lin.weight_mask', 'distilbert.transformer.layer.0.attention.q_lin.weight_orig', 'distilbert.transformer.layer.0.attention.v_lin.weight_mask', 'distilbert.transformer.layer.0.attention.v_lin.weight_orig', 'distilbert.transformer.layer.0.ffn.lin1.weight_mask', 'distilbert.transformer.layer.0.ffn.lin1.weight_orig', 'distilbert.transformer.layer.0.ffn.lin2.weight_mask', 'distilbert.transformer.layer.0.ffn.lin2.weight_orig', 'distilbert.transformer.layer.1.attention.k_lin.weight_mask', 'distilbert.transformer.layer.1.attention.k_lin.weight_orig', 'distilbert.transformer.layer.1.attention.out_lin.weight_mask', 'distilbert.transformer.layer.1.attention.out_lin.weight_orig', 'distilbert.transformer.layer.1.attention.q_lin.weight_mask', 'distilbert.transformer.layer.1.attention.q_lin.weight_orig', 'distilbert.transformer.layer.1.attention.v_lin.weight_mask', 'distilbert.transformer.layer.1.attention.v_lin.weight_orig', 'distilbert.transformer.layer.1.ffn.lin1.weight_mask', 'distilbert.transformer.layer.1.ffn.lin1.weight_orig', 'distilbert.transformer.layer.1.ffn.lin2.weight_mask', 'distilbert.transformer.layer.1.ffn.lin2.weight_orig', 'distilbert.transformer.layer.2.attention.k_lin.weight_mask', 'distilbert.transformer.layer.2.attention.k_lin.weight_orig', 'distilbert.transformer.layer.2.attention.out_lin.weight_mask', 'distilbert.transformer.layer.2.attention.out_lin.weight_orig', 'distilbert.transformer.layer.2.attention.q_lin.weight_mask', 'distilbert.transformer.layer.2.attention.q_lin.weight_orig', 'distilbert.transformer.layer.2.attention.v_lin.weight_mask', 'distilbert.transformer.layer.2.attention.v_lin.weight_orig', 'distilbert.transformer.layer.2.ffn.lin1.weight_mask', 'distilbert.transformer.layer.2.ffn.lin1.weight_orig', 'distilbert.transformer.layer.2.ffn.lin2.weight_mask', 'distilbert.transformer.layer.2.ffn.lin2.weight_orig', 'distilbert.transformer.layer.3.attention.k_lin.weight_mask', 'distilbert.transformer.layer.3.attention.k_lin.weight_orig', 'distilbert.transformer.layer.3.attention.out_lin.weight_mask', 'distilbert.transformer.layer.3.attention.out_lin.weight_orig', 'distilbert.transformer.layer.3.attention.q_lin.weight_mask', 'distilbert.transformer.layer.3.attention.q_lin.weight_orig', 'distilbert.transformer.layer.3.attention.v_lin.weight_mask', 'distilbert.transformer.layer.3.attention.v_lin.weight_orig', 'distilbert.transformer.layer.3.ffn.lin1.weight_mask', 'distilbert.transformer.layer.3.ffn.lin1.weight_orig', 'distilbert.transformer.layer.3.ffn.lin2.weight_mask', 'distilbert.transformer.layer.3.ffn.lin2.weight_orig', 'distilbert.transformer.layer.4.attention.k_lin.weight_mask', 'distilbert.transformer.layer.4.attention.k_lin.weight_orig', 'distilbert.transformer.layer.4.attention.out_lin.weight_mask', 'distilbert.transformer.layer.4.attention.out_lin.weight_orig', 'distilbert.transformer.layer.4.attention.q_lin.weight_mask', 'distilbert.transformer.layer.4.attention.q_lin.weight_orig', 'distilbert.transformer.layer.4.attention.v_lin.weight_mask', 'distilbert.transformer.layer.4.attention.v_lin.weight_orig', 'distilbert.transformer.layer.4.ffn.lin1.weight_mask', 'distilbert.transformer.layer.4.ffn.lin1.weight_orig', 'distilbert.transformer.layer.4.ffn.lin2.weight_mask', 'distilbert.transformer.layer.4.ffn.lin2.weight_orig', 'distilbert.transformer.layer.5.attention.k_lin.weight_mask', 'distilbert.transformer.layer.5.attention.k_lin.weight_orig', 'distilbert.transformer.layer.5.attention.out_lin.weight_mask', 'distilbert.transformer.layer.5.attention.out_lin.weight_orig', 'distilbert.transformer.layer.5.attention.q_lin.weight_mask', 'distilbert.transformer.layer.5.attention.q_lin.weight_orig', 'distilbert.transformer.layer.5.attention.v_lin.weight_mask', 'distilbert.transformer.layer.5.attention.v_lin.weight_orig', 'distilbert.transformer.layer.5.ffn.lin1.weight_mask', 'distilbert.transformer.layer.5.ffn.lin1.weight_orig', 'distilbert.transformer.layer.5.ffn.lin2.weight_mask', 'distilbert.transformer.layer.5.ffn.lin2.weight_orig', 'pre_classifier.weight_mask', 'pre_classifier.weight_orig']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at ./pruned_sentiment_model and are newly initialized: ['classifier.weight', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 모델 파라미터 수:\n",
      " - 전체 파라미터: 66955010\n",
      " - 0인 파라미터: 0\n",
      " - 학습 가능한 파라미터: 66955010\n",
      "\n",
      "Pruned 모델 파라미터 수:\n",
      " - 전체 파라미터: 66955010\n",
      " - 0인 파라미터: 5\n",
      " - 학습 가능한 파라미터: 66955010\n",
      "\n",
      "Pruning 효과: 전체 파라미터의 0.00%가 0으로 설정되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# 모델 경로\n",
    "original_model_path = \"distilbert-base-uncased-finetuned-sst-2-english\"  # 원래 모델\n",
    "pruned_model_path = \"./pruned_sentiment_model\"  # Pruning된 모델\n",
    "\n",
    "# 1. 모델 로드\n",
    "original_model = AutoModelForSequenceClassification.from_pretrained(original_model_path)\n",
    "pruned_model = AutoModelForSequenceClassification.from_pretrained(pruned_model_path)\n",
    "\n",
    "# 2. 파라미터 수 계산 함수\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())  # 전체 파라미터 수\n",
    "    zero_params = sum((p == 0).sum().item() for p in model.parameters() if p.requires_grad)  # 0인 파라미터 수\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)  # 학습 가능한 파라미터 수\n",
    "    return total_params, zero_params, trainable_params\n",
    "\n",
    "# 3. 원래 모델 파라미터 수 계산\n",
    "original_total, original_zero, original_trainable = count_parameters(original_model)\n",
    "print(f\"원래 모델 파라미터 수:\")\n",
    "print(f\" - 전체 파라미터: {original_total}\")\n",
    "print(f\" - 0인 파라미터: {original_zero}\")\n",
    "print(f\" - 학습 가능한 파라미터: {original_trainable}\")\n",
    "\n",
    "# 4. Pruned 모델 파라미터 수 계산\n",
    "pruned_total, pruned_zero, pruned_trainable = count_parameters(pruned_model)\n",
    "print(f\"\\nPruned 모델 파라미터 수:\")\n",
    "print(f\" - 전체 파라미터: {pruned_total}\")\n",
    "print(f\" - 0인 파라미터: {pruned_zero}\")\n",
    "print(f\" - 학습 가능한 파라미터: {pruned_trainable}\")\n",
    "\n",
    "# 5. Pruning 효과 비교\n",
    "pruned_ratio = pruned_zero / pruned_total * 100\n",
    "print(f\"\\nPruning 효과: 전체 파라미터의 {pruned_ratio:.2f}%가 0으로 설정되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned 모델에서 불필요한 파라미터 제거 후 총 파라미터 수: 66955010\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def remove_pruned_weights(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if hasattr(module, \"weight_orig\"):\n",
    "            # Pruning된 가중치를 제거하고 새로운 Dense 가중치로 교체\n",
    "            module.weight = torch.nn.Parameter(module.weight.detach())\n",
    "            del module.weight_orig\n",
    "            del module.weight_mask\n",
    "    return model\n",
    "\n",
    "# Pruned 모델에서 불필요한 파라미터 제거\n",
    "pruned_dense_model = remove_pruned_weights(pruned_model)\n",
    "\n",
    "# 파라미터 수 다시 확인\n",
    "total_params = sum(p.numel() for p in pruned_dense_model.parameters())\n",
    "print(f\"Pruned 모델에서 불필요한 파라미터 제거 후 총 파라미터 수: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
